{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"U3y0JUEVu_Zu"},"outputs":[],"source":["!pip install google-auth google-auth-httplib2 google-auth-oauthlib google-api-python-client\n","!pip install -q -U google-generativeai\n","!pip install --upgrade google-generativeai"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EA5yFjUmrkRm"},"outputs":[],"source":["#Import necessary libraries\n","from google.oauth2 import service_account\n","from googleapiclient.discovery import build"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8IkheaXGsir1"},"outputs":[],"source":["import openpyxl\n","from openai import OpenAI\n","import os\n","import json\n","from tqdm import tqdm\n","import pandas as pd\n","import google.generativeai as genai"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MbiAI6m8sL3J"},"outputs":[],"source":["# Import the API Key (blinded)\n","GOOGLE_API_KEY=\"\"\n","genai.configure(api_key=GOOGLE_API_KEY)"]},{"cell_type":"markdown","metadata":{"id":"qmGkH0WztTIc"},"source":["# Reading G-Drive Sheet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vy8VfjjdtJsh"},"outputs":[],"source":["!pip install --quiet gspread oauth2client google-auth\n","import gspread\n","from google.colab import auth\n","import pandas as pd\n","import google.auth\n","\n","auth.authenticate_user()\n","\n","# Authorize gspread client\n","credentials, project = google.auth.default()\n","gc = gspread.authorize(credentials)\n","\n","def load_sheet(sheet_id, sheet_name=\"Sheet1\"):\n","    # Load google sheet as dataframe\n","    worksheet = gc.open_by_key(sheet_id).worksheet(sheet_name)\n","    data = worksheet.get_all_values()\n","    df = pd.DataFrame(data[1:], columns=data[0])\n","    return df\n","#path blinded\n","path = \"\"\n","sheet = load_sheet(path,\"roseWangResponses_mapped_20251112\")"]},{"cell_type":"markdown","metadata":{"id":"5uKQIYXct0_j"},"source":["Get all the responses and scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SaaEXbQ_tjSs"},"outputs":[],"source":["INPUT_COLUMN = \"response\" # Specify the column from which input is read\n","sheet = sheet[(sheet[\"title\"]==\"Asking Questions to Guide Thinking\") & (sheet[\"prompt\"].str.startswith((\"1.\",\"9.\")))]\n","sheet = sheet.reset_index(drop=True)\n","row_count = len(sheet) # Get number of rows.\n","inputs = [sheet.loc[i, INPUT_COLUMN] for i in range(row_count)]\n","inputs = [x for x in inputs if x is not None]\n","print(inputs)"]},{"cell_type":"markdown","metadata":{"id":"qASEYdU1vH08"},"source":["# Gemini Prompt Setup"]},{"cell_type":"markdown","metadata":{"id":"cKg2bQ7qvi_i"},"source":["Scoring Prompt Input"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wfyoLemuvkrN"},"outputs":[],"source":["GEMINI_SYSTEM_PROMPT = \"\"\"\n","You are a tutor evaluator. Please score the following tutor response to a tutor training scenario involving a middle school student:\n","-if the tutor’s response uses guiding questions to encourage the student to reflect or think critically, score with a 1. Sample responses scoring a 1 are \"You've got this, Tvisha! What would be the case if the area was 50 square units?\" and \"Matthias, nice effort so far! Is there any other operation you should do before dividing?\".\n","-if the tutor’s response asks questions with simple answers that don’t give the student space to think on their own, or doesn't ask a question at all, score with a 0. Sample responses scoring a 0 are \"I would ask him what he would get after dividing by 4.\" and \"Do we want to try other questions.\"; \"Do you have any questions about the method?.\"\n","\n","Once given a response by the user, please return a JSON string following the format, {\"Rationale\": \"your reasoning here\", \"Score\":0/1}\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"VuVI8e8kxT87"},"source":["Helper function for response parsing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uIlxCT-ixV5J"},"outputs":[],"source":["def extract_response(response_obj, json=False):\n","  role = response_obj.choices[0].message.role\n","  content = response_obj.choices[0].message.content\n","  if json:\n","    return {\"role\": role, \"content\": content}\n","  else:\n","    return (role, content)"]},{"cell_type":"markdown","metadata":{"id":"jIHBTOqTwW1T"},"source":["## gemini API Call"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ms4Iojj3wWGw"},"outputs":[],"source":["# Iterate over all responses\n","MAX_TOKENS = 300\n","TEMPERATURE = 0\n","RUN_UP_TO = 296  # Sets a maximum index for responses to run. Useful to specify how many responses we want to run on (partial execution). Set to -1 to run them all.\n","SCORE_COLUMN = \"response\"  # Change column numbers here to  modify where output is written\n","\n","\n","MODEL = 'gemini-2.5-pro'\n","model = genai.GenerativeModel(MODEL, system_instruction=GEMINI_SYSTEM_PROMPT)\n","\n","\n","if RUN_UP_TO >=  0:  # If an upper bound is set\n","  inputs_upto = inputs[:RUN_UP_TO]\n","else:\n","  inputs_upto = inputs  # Take the whole set of responses\n","tempScoreList = []\n","tempDirectionList = []\n","tempRationaleList = []\n","\n","for index, inpt in tqdm(enumerate(inputs_upto), total=len(inputs_upto)):\n","  generation_prompt = \"Tutor Response: \" + inpt + \"\\n\\n. Your JSON: \"\n","  generation_config = genai.GenerationConfig(temperature=TEMPERATURE)\n","  gemini_out = model.generate_content(generation_prompt, generation_config=generation_config)\n","  print(gemini_out)\n","  # Extract the content from the response\n","  content = gemini_out.text.lstrip(\"```json\")[:-4]\n","  print(content)\n","  # We now need to parse the JSON into rationale and score\n","  try:\n","    content_json = json.loads(content)  # Run response through JSON\n","    score = str(content_json[\"Score\"])  # Cast to string to avoid type inequality\n","    rationale = str(content_json[\"Rationale\"])  # Fetch the rationale\n","    sheet.at[index,\"Gemini Score\"] = score  # Now write both into the dataframe\n","    sheet.at[index,\"Gemini Rationale\"] = rationale\n","    tempScoreList.append(score)\n","    tempDirectionList.append(generation_prompt)\n","    tempRationaleList.append(rationale)\n","\n","  except:\n","    print(\"error!\")\n","\n","print(tempScoreList)\n","print(tempDirectionList)\n","print(tempRationaleList)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUPYEvCt4bP9"},"outputs":[],"source":["for i in range(len(inputs_upto)):\n","  print(inputs_upto[i])\n","  print(tempScoreList[i])\n","  print(tempRationaleList[i])\n","  print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BzJmfvbvUaiU"},"outputs":[],"source":["print(list(sheet[\"Gemini Score\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e7MWojh7Y0pg"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"Pvd9C9skROrl"},"source":["## Save G-Drive Sheet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GckhEy2oRNme"},"outputs":[],"source":["#blinded\n","sheet.to_csv('', index=False)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1R9Gi6Ckdan1j8R2HqdWAc3DBeL5dLE-5","timestamp":1769521673713},{"file_id":"1MX8lDX5l7s1nyJwpr_fpl66cdYKKCq_x","timestamp":1763733004688},{"file_id":"1uGz8Usm0L7SeJAjcViKm3i4R7jpTVKAG","timestamp":1762869275116},{"file_id":"10pv6Rzj4KmLo3M-66o7JQWYlRkJsZKks","timestamp":1713375895284}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
