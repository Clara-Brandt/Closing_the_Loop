{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"U3y0JUEVu_Zu"},"outputs":[],"source":["!pip install google-auth google-auth-httplib2 google-auth-oauthlib google-api-python-client\n","!pip install -q -U google-generativeai\n","!pip install --upgrade google-generativeai"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EA5yFjUmrkRm"},"outputs":[],"source":["#Import necessary libraries\n","from google.oauth2 import service_account\n","from googleapiclient.discovery import build"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8IkheaXGsir1"},"outputs":[],"source":["import openpyxl\n","from openai import OpenAI\n","import os\n","import json\n","from tqdm import tqdm\n","import pandas as pd\n","import google.generativeai as genai\n","from google.generativeai.types import RequestOptions\n","from google.api_core import retry\n","import time"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MbiAI6m8sL3J"},"outputs":[],"source":["# Import the API Key (key blinded)\n","GOOGLE_API_KEY=\"\"\n","genai.configure(api_key=GOOGLE_API_KEY)"]},{"cell_type":"markdown","metadata":{"id":"qmGkH0WztTIc"},"source":["# Reading G-Drive Sheet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vy8VfjjdtJsh"},"outputs":[],"source":["!pip install --quiet gspread oauth2client google-auth\n","import gspread\n","from google.colab import auth\n","import pandas as pd\n","import google.auth\n","\n","auth.authenticate_user()\n","\n","# Authorize gspread client\n","credentials, project = google.auth.default()\n","gc = gspread.authorize(credentials)\n","\n","def load_sheet(sheet_id, sheet_name=\"Sheet1\"):\n","    # Load google sheet as dataframe\n","    worksheet = gc.open_by_key(sheet_id).worksheet(sheet_name)\n","    data = worksheet.get_all_values()\n","    df = pd.DataFrame(data[1:], columns=data[0])\n","    return df\n","\n","#path blinded\n","path = \"\"\n","sheet = load_sheet(path,\"Giving Effective Praise Predict_responses\")"]},{"cell_type":"markdown","metadata":{"id":"5uKQIYXct0_j"},"source":["Get all the responses and scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SaaEXbQ_tjSs"},"outputs":[],"source":["INPUT_COLUMN = \"response\" # Specify the column from which input is read\n","row_count = len(sheet) # Get number of rows.\n","inputs = [sheet.loc[i, INPUT_COLUMN] for i in range(row_count)]\n","inputs = [x for x in inputs if x is not None]\n","print(inputs)\n","print(len(inputs))"]},{"cell_type":"markdown","metadata":{"id":"qASEYdU1vH08"},"source":["# Gemini Prompt Setup"]},{"cell_type":"markdown","metadata":{"id":"cKg2bQ7qvi_i"},"source":["Scoring Prompt Input"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wfyoLemuvkrN"},"outputs":[],"source":["GEMINI_SYSTEM_PROMPT = \"\"\"\n","You are a tutor evaluator. Please score the following tutor response to a tutor training scenario involving a middle school student as follows:\n","-if the tutor’s response provides effective, process-focused praise that acknowledges the student’s effort, hard work, perseverance, or focuses on the student’s actions towards the learning process, score with a 1. Examples of responses scoring a 1 are: “Kevin, you didn't give up and you managed to learn, congratulations! Let's finish your math homework together so you can still get a good grade and learn how this kind of homework will be easier sooner.”; “Keep Working.”; “Great job Kevin! You are on the right track, keep working on the problem, you get it!”; “Kevin, that was awesome the way you kept at it and were able to get to the correct answer. You should be proud. Keep up the great work!”; “You're doing a great job working on this paragraph! It can be tricky to find the right words and I think you're doing really well working through it.”\n","-if the tutor's response provides outcomes-based praise, acknowledging only the student’s achievements or outcomes, or does not acknowledge the learning process or effort towards learning, score with a 0. Sample responses scoring a 0 include: “You're doing great, let's see what the next step is.”; “Good Job.”; “I would say she is doing well and let us explore a bit more.”; “I think you are doing great.”; “You can do this! Just take it one step at a time.”\n","Once given a response by the user, please return a JSON string following the format, {\"Rationale\": \"your reasoning here\", \"Score\":0/1}\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"VuVI8e8kxT87"},"source":["Helper function for response parsing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uIlxCT-ixV5J"},"outputs":[],"source":["def extract_response(response_obj, json=False):\n","  role = response_obj.choices[0].message.role\n","  content = response_obj.choices[0].message.content\n","  if json:\n","    return {\"role\": role, \"content\": content}\n","  else:\n","    return (role, content)"]},{"cell_type":"markdown","metadata":{"id":"jIHBTOqTwW1T"},"source":["## gemini API Call"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ms4Iojj3wWGw"},"outputs":[],"source":["# Iterate over all responses\n","MAX_TOKENS = 300\n","TEMPERATURE = 0\n","RUN_UP_TO = 250  # Sets a maximum index for responses to run. Useful to specify how many responses we want to run on (partial execution). Set to -1 to run them all.\n","SCORE_COLUMN = \"response\"  # Change column numbers here to  modify where output is written\n","\n","\n","MODEL = 'gemini-2.5-pro'\n","model = genai.GenerativeModel(MODEL, system_instruction=GEMINI_SYSTEM_PROMPT)\n","\n","if RUN_UP_TO >=  0:  # If an upper bound is set\n","  inputs_upto = inputs[:RUN_UP_TO]\n","else:\n","  inputs_upto = inputs  # Take the whole set of responses\n","tempScoreList = []\n","tempDirectionList = []\n","tempRationaleList = []\n","retries = []\n","\n","for index, inpt in tqdm(enumerate(inputs_upto), total=len(inputs_upto)):\n","  if index%60 == 0:\n","    time.sleep(30)\n","  generation_prompt = \"Tutor Response: \" + inpt + \"\\n\\n. Your JSON: \"\n","  generation_config = genai.GenerationConfig(temperature=TEMPERATURE)\n","  gemini_out = model.generate_content(generation_prompt, generation_config=generation_config,request_options=RequestOptions(retry=retry.Retry(initial=1.0,multiplier=2.0,maximum=60.0)))\n","  # Extract the content from the response\n","  content = gemini_out.text.lstrip(\"```json\")[:-4]\n","  # We now need to parse the JSON into rational and score\n","  try:\n","    content_json = json.loads(content)  # Run response through JSON\n","    score = str(content_json[\"Score\"])  # Cast to string to avoid type inequality\n","    rationale = str(content_json[\"Rationale\"])  # Fetch the rationale\n","    sheet.at[index,\"Gemini Score\"] = score  # Now write both into the dataframe\n","    sheet.at[index,\"Gemini Rationale\"] = rationale\n","    tempScoreList.append(score)\n","    tempDirectionList.append(generation_prompt)\n","    tempRationaleList.append(rationale)\n","\n","  except:\n","    print(\"error!\")\n","    tempScoreList.append(\"error during LLM evaluation\")\n","    tempRationaleList.append(\"error during LLM evaluation\")\n","    retries.append((index,inpt))\n","\n","print(tempScoreList)\n","print(tempDirectionList)\n","print(tempRationaleList)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cXIjAG544f3I"},"outputs":[],"source":["print(tempScoreList)\n","print(tempRationaleList)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUPYEvCt4bP9"},"outputs":[],"source":["for i in range(len(inputs_upto)):\n","  print(inputs_upto[i])\n","  print(tempScoreList[i])\n","  print(tempRationaleList[i])\n","  print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BzJmfvbvUaiU"},"outputs":[],"source":["print(list(sheet[\"Gemini Score\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e7MWojh7Y0pg"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"Pvd9C9skROrl"},"source":["## Save G-Drive Sheet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GckhEy2oRNme"},"outputs":[],"source":["#path blinded\n","sheet.to_csv('', index=False)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1v0VLwkjaoDYxNL4X9m8hGhwDwiUyFkHa","timestamp":1770315686313},{"file_id":"18Bv9gL9hm4WauNbfvPr0PnUWcGqo8YOF","timestamp":1765784929094},{"file_id":"1AqdXS2kqbCifoA8GeUb51sqE-alN3Mti","timestamp":1765784592164},{"file_id":"12945bvJDRvEQHz7paDNIzeZ0eG2JN6Yj","timestamp":1765783524204},{"file_id":"1R9Gi6Ckdan1j8R2HqdWAc3DBeL5dLE-5","timestamp":1765755530310},{"file_id":"1MX8lDX5l7s1nyJwpr_fpl66cdYKKCq_x","timestamp":1763733004688},{"file_id":"1uGz8Usm0L7SeJAjcViKm3i4R7jpTVKAG","timestamp":1762869275116},{"file_id":"10pv6Rzj4KmLo3M-66o7JQWYlRkJsZKks","timestamp":1713375895284}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
