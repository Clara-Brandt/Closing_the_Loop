{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"U3y0JUEVu_Zu"},"outputs":[],"source":["!pip install google-auth google-auth-httplib2 google-auth-oauthlib google-api-python-client\n","!pip install -q -U google-generativeai\n","!pip install --upgrade google-generativeai"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EA5yFjUmrkRm"},"outputs":[],"source":["#Import necessary libraries\n","from google.oauth2 import service_account\n","from googleapiclient.discovery import build"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8IkheaXGsir1"},"outputs":[],"source":["import openpyxl\n","from openai import OpenAI\n","import os\n","import json\n","from tqdm import tqdm\n","import pandas as pd\n","import google.generativeai as genai\n","import time\n","from google.generativeai.types import RequestOptions\n","from google.api_core import retry"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MbiAI6m8sL3J"},"outputs":[],"source":["# Import the API Key (blinded)\n","GOOGLE_API_KEY=\"\"\n","genai.configure(api_key=GOOGLE_API_KEY)"]},{"cell_type":"markdown","metadata":{"id":"qmGkH0WztTIc"},"source":["# Reading G-Drive Sheet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vy8VfjjdtJsh"},"outputs":[],"source":["!pip install --quiet gspread oauth2client google-auth\n","import gspread\n","from google.colab import auth\n","import pandas as pd\n","import google.auth\n","\n","auth.authenticate_user()\n","\n","# Authorize gspread client\n","credentials, project = google.auth.default()\n","gc = gspread.authorize(credentials)\n","\n","def load_sheet(sheet_id, sheet_name=\"Sheet1\"):\n","    # Load google sheet as dataframe\n","    worksheet = gc.open_by_key(sheet_id).worksheet(sheet_name)\n","    data = worksheet.get_all_values()\n","    df = pd.DataFrame(data[1:], columns=data[0])\n","    return df\n","\n","#(path blinded)\n","path = \"\"\n","sheet = load_sheet(path,\"Reacting to Errors Predict_responses\")"]},{"cell_type":"markdown","metadata":{"id":"5uKQIYXct0_j"},"source":["Get all the responses and scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SaaEXbQ_tjSs"},"outputs":[],"source":["INPUT_COLUMN = \"response\" # Specify the column from which input is read\n","row_count = len(sheet) # Get number of rows\n","inputs = [sheet.loc[i, INPUT_COLUMN] for i in range(row_count)]\n","inputs = [x for x in inputs if x is not None]\n","print(inputs)"]},{"cell_type":"markdown","metadata":{"id":"qASEYdU1vH08"},"source":["# Gemini Prompt Setup"]},{"cell_type":"markdown","metadata":{"id":"cKg2bQ7qvi_i"},"source":["Scoring Prompt Input"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wfyoLemuvkrN"},"outputs":[],"source":["GEMINI_SYSTEM_PROMPT = \"\"\"\n","You are a tutor evaluator. Please score the following tutor response to a tutor training scenario involving a middle school student making a math error as follows:\n","-If the tutor’s response provides an implicit way of calling attention to the error and focuses on encouraging students thinking about math and  metacognition rather than giving explicit answers, score with a 1. Examples of responses scoring a 1 are: “Lucy, great start! Explain how you passed to the second column”; “Thank you for showing me your work, Lucy. You worked hard on adding these numbers. I am going to work on this problem with you. Can you tell me how you added the numbers first?”; “Well done setting up the problem, Lucy. Can you tell me how you went about calculating the first few steps?”; “I like your effort, but show me what you are trying to do in the second step”; “Kanye, very well done. Your effort was very valuable. Can you repeat how you arrived at this result? Let's do this problem together”; “Hi Aaron, you made a good try. Could you explain your calculation step for me?”; and “I got a different answer. Let's look at this together.”\n","-If the tutor's response addresses the student’s error using explicit language by directly calling attention to the student’s error, or fails to encourage the student to think about math and reflect on their thought process, score with a 0. Sample responses scoring a 0 include: “Let's try solving the problem together.”; “Good effort.”; ; “Do you know about carrying the 1?”; “Kanye, let me show you how this should be done”; “Great attempt! You've just to change one thing to make the answer correct”; and “You’re very close, but not completely correct. Would you mind walking me through how you set up this problem?”\n","Once given a response by the user, please return a JSON string following the format, {\"Rationale\": \"your reasoning here\", \"Score\":0/1}\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"VuVI8e8kxT87"},"source":["Helper function for response parsing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uIlxCT-ixV5J"},"outputs":[],"source":["def extract_response(response_obj, json=False):\n","  role = response_obj.choices[0].message.role\n","  content = response_obj.choices[0].message.content\n","  if json:\n","    return {\"role\": role, \"content\": content}\n","  else:\n","    return (role, content)"]},{"cell_type":"markdown","metadata":{"id":"jIHBTOqTwW1T"},"source":["## gemini API Call"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ms4Iojj3wWGw"},"outputs":[],"source":["# Iterate over all responses\n","MAX_TOKENS = 300\n","TEMPERATURE = 0\n","RUN_UP_TO = 256  # Sets a maximum index for responses to run. Useful to specify how many responses we want to run on (partial execution). Set to -1 to run them all.\n","SCORE_COLUMN = \"response\"  # Change column numbers here to  modify where output is written\n","\n","MODEL = 'gemini-2.5-pro'\n","model = genai.GenerativeModel(MODEL, system_instruction=GEMINI_SYSTEM_PROMPT)\n","\n","if RUN_UP_TO >=  0:  # If an upper bound is set\n","  inputs_upto = inputs[:RUN_UP_TO]\n","else:\n","  inputs_upto = inputs  # Take the whole set of responses\n","tempScoreList = []\n","tempDirectionList = []\n","tempRationaleList = []\n","retries = []\n","\n","for index, inpt in tqdm(enumerate(inputs_upto), total=len(inputs_upto)):\n","  if index%60 == 0:\n","    time.sleep(30)\n","  generation_prompt = \"Tutor Response: \" + inpt + \"\\n\\n. Your JSON: \" # Gemini Change\n","  generation_config = genai.GenerationConfig(temperature=TEMPERATURE)\n","  gemini_out = model.generate_content(generation_prompt, generation_config=generation_config,request_options=RequestOptions(retry=retry.Retry(initial=1.0,multiplier=2.0,maximum=60.0,timeout=300.0)))\n","  # Extract the content from the response\n","  content = gemini_out.text.lstrip(\"```json\")[:-4]\n","  # We now need to parse the JSON into rationale and score\n","  try:\n","    content_json = json.loads(content)  # Run response through JSON\n","    score = str(content_json[\"Score\"])  # Cast to string to avoid type inequality\n","    rationale = str(content_json[\"Rationale\"])  # Fetch the rationale\n","    sheet.at[index,\"Gemini Score\"] = score  # Now write both into the dataframe\n","    sheet.at[index,\"Gemini Rationale\"] = rationale\n","    tempScoreList.append(score)\n","    tempDirectionList.append(generation_prompt)\n","    tempRationaleList.append(rationale)\n","\n","  except:\n","    print(\"error!\")\n","    tempScoreList.append(\"error during LLM evaluation\")\n","    tempRationaleList.append(\"error during LLM evaluation\")\n","    retries.append((index,inpt))\n","\n","print(tempScoreList)\n","print(tempDirectionList)\n","print(tempRationaleList)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUPYEvCt4bP9"},"outputs":[],"source":["for i in range(len(inputs_upto)):\n","  print(inputs_upto[i])\n","  print(tempScoreList[i])\n","  print(tempRationaleList[i])\n","  print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BzJmfvbvUaiU"},"outputs":[],"source":["print(list(sheet[\"Gemini Score\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e7MWojh7Y0pg"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"Pvd9C9skROrl"},"source":["## Save Sheet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GckhEy2oRNme"},"outputs":[],"source":["#path blinded\n","sheet.to_csv('', index=False)"]}],"metadata":{"colab":{"provenance":[{"file_id":"12945bvJDRvEQHz7paDNIzeZ0eG2JN6Yj","timestamp":1769521121624},{"file_id":"1R9Gi6Ckdan1j8R2HqdWAc3DBeL5dLE-5","timestamp":1765755530310},{"file_id":"1MX8lDX5l7s1nyJwpr_fpl66cdYKKCq_x","timestamp":1763733004688},{"file_id":"1uGz8Usm0L7SeJAjcViKm3i4R7jpTVKAG","timestamp":1762869275116},{"file_id":"10pv6Rzj4KmLo3M-66o7JQWYlRkJsZKks","timestamp":1713375895284}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
